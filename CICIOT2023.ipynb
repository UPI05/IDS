{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10978,"status":"ok","timestamp":1705010650990,"user":{"displayName":"Hiếu Võ","userId":"16914104909337499796"},"user_tz":-420},"id":"ci7lGMIlWDOi"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-01-19 16:30:20.269412: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-01-19 16:30:20.349161: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-19 16:30:20.349224: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-19 16:30:20.349286: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-19 16:30:20.366333: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-01-19 16:30:20.367909: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-01-19 16:30:22.479010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import glob\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import SGD, Adam\n","from tensorflow.keras.layers import Dropout\n","from tqdm import tqdm\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["dict_2classes = {}\n","dict_2classes['DDoS-RSTFINFlood'] = 'Attack'\n","dict_2classes['DDoS-PSHACK_Flood'] = 'Attack'\n","dict_2classes['DDoS-SYN_Flood'] = 'Attack'\n","dict_2classes['DDoS-UDP_Flood'] = 'Attack'\n","dict_2classes['DDoS-TCP_Flood'] = 'Attack'\n","dict_2classes['DDoS-ICMP_Flood'] = 'Attack'\n","dict_2classes['DDoS-SynonymousIP_Flood'] = 'Attack'\n","dict_2classes['DDoS-ACK_Fragmentation'] = 'Attack'\n","dict_2classes['DDoS-UDP_Fragmentation'] = 'Attack'\n","dict_2classes['DDoS-ICMP_Fragmentation'] = 'Attack'\n","dict_2classes['DDoS-SlowLoris'] = 'Attack'\n","dict_2classes['DDoS-HTTP_Flood'] = 'Attack'\n","\n","dict_2classes['DoS-UDP_Flood'] = 'Attack'\n","dict_2classes['DoS-SYN_Flood'] = 'Attack'\n","dict_2classes['DoS-TCP_Flood'] = 'Attack'\n","dict_2classes['DoS-HTTP_Flood'] = 'Attack'\n","\n","\n","dict_2classes['Mirai-greeth_flood'] = 'Attack'\n","dict_2classes['Mirai-greip_flood'] = 'Attack'\n","dict_2classes['Mirai-udpplain'] = 'Attack'\n","\n","dict_2classes['Recon-PingSweep'] = 'Attack'\n","dict_2classes['Recon-OSScan'] = 'Attack'\n","dict_2classes['Recon-PortScan'] = 'Attack'\n","dict_2classes['VulnerabilityScan'] = 'Attack'\n","dict_2classes['Recon-HostDiscovery'] = 'Attack'\n","\n","dict_2classes['DNS_Spoofing'] = 'Attack'\n","dict_2classes['MITM-ArpSpoofing'] = 'Attack'\n","\n","dict_2classes['BenignTraffic'] = 'Benign'\n","\n","dict_2classes['BrowserHijacking'] = 'Attack'\n","dict_2classes['Backdoor_Malware'] = 'Attack'\n","dict_2classes['XSS'] = 'Attack'\n","dict_2classes['Uploading_Attack'] = 'Attack'\n","dict_2classes['SqlInjection'] = 'Attack'\n","dict_2classes['CommandInjection'] = 'Attack'\n","\n","dict_2classes['DictionaryBruteForce'] = 'Attack'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#df = pd.read_csv('./filtered_data2.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["file_paths len:  169\n"]},{"name":"stderr","output_type":"stream","text":["Processing files: 100%|██████████| 51/51 [02:51<00:00,  3.36s/file]\n"]}],"source":["file_paths = glob.glob('/home/haohao/Downloads/archive/wataiData/csv/CICIoT2023/*.csv')\n","file_paths.sort()\n","print('file_paths len: ', len(file_paths))\n","df = pd.DataFrame()\n","for file_path in tqdm(file_paths[:round(len(file_paths) * 0.3)], desc='Processing files', unit='file'):\n","    dff = pd.read_csv(file_path)\n","    df = pd.concat([df, dff], ignore_index=True)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["df['label'] = df['label'].map(dict_2classes)\n","df = df.sample(frac=1, random_state=42)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>flow_duration</th>\n","      <th>Header_Length</th>\n","      <th>Protocol Type</th>\n","      <th>Duration</th>\n","      <th>Rate</th>\n","      <th>Srate</th>\n","      <th>Drate</th>\n","      <th>fin_flag_number</th>\n","      <th>syn_flag_number</th>\n","      <th>rst_flag_number</th>\n","      <th>...</th>\n","      <th>Std</th>\n","      <th>Tot size</th>\n","      <th>IAT</th>\n","      <th>Number</th>\n","      <th>Magnitue</th>\n","      <th>Radius</th>\n","      <th>Covariance</th>\n","      <th>Variance</th>\n","      <th>Weight</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5279460</th>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>6.00</td>\n","      <td>64.00</td>\n","      <td>11.306346</td>\n","      <td>11.306346</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>8.334454e+07</td>\n","      <td>9.5</td>\n","      <td>10.392305</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","    <tr>\n","      <th>6663301</th>\n","      <td>0.145200</td>\n","      <td>217.75</td>\n","      <td>6.99</td>\n","      <td>63.59</td>\n","      <td>29.517406</td>\n","      <td>29.517406</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>9.031879</td>\n","      <td>66.19</td>\n","      <td>8.297354e+07</td>\n","      <td>9.5</td>\n","      <td>10.885608</td>\n","      <td>12.765440</td>\n","      <td>541.688358</td>\n","      <td>0.29</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","    <tr>\n","      <th>8559664</th>\n","      <td>0.008476</td>\n","      <td>13.74</td>\n","      <td>1.42</td>\n","      <td>66.31</td>\n","      <td>12.492760</td>\n","      <td>12.492760</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>549.066680</td>\n","      <td>920.22</td>\n","      <td>8.325338e+07</td>\n","      <td>9.5</td>\n","      <td>41.775523</td>\n","      <td>776.392424</td>\n","      <td>317509.558997</td>\n","      <td>0.95</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","    <tr>\n","      <th>6299347</th>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>6.00</td>\n","      <td>64.00</td>\n","      <td>60.940691</td>\n","      <td>60.940691</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>8.334495e+07</td>\n","      <td>9.5</td>\n","      <td>10.392305</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","    <tr>\n","      <th>9878162</th>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>6.00</td>\n","      <td>64.00</td>\n","      <td>31.855998</td>\n","      <td>31.855998</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>8.297255e+07</td>\n","      <td>9.5</td>\n","      <td>10.392305</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","    <tr>\n","      <th>5980310</th>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>6.00</td>\n","      <td>64.00</td>\n","      <td>4.574341</td>\n","      <td>4.574341</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>8.306855e+07</td>\n","      <td>9.5</td>\n","      <td>10.392305</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","    <tr>\n","      <th>9817752</th>\n","      <td>0.000000</td>\n","      <td>160.38</td>\n","      <td>16.83</td>\n","      <td>63.36</td>\n","      <td>0.473485</td>\n","      <td>0.473485</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.959534</td>\n","      <td>160.98</td>\n","      <td>8.301122e+07</td>\n","      <td>9.5</td>\n","      <td>17.971541</td>\n","      <td>2.778919</td>\n","      <td>48.451831</td>\n","      <td>0.08</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","    <tr>\n","      <th>8683320</th>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>64.00</td>\n","      <td>36.340593</td>\n","      <td>36.340593</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>42.00</td>\n","      <td>8.314999e+07</td>\n","      <td>9.5</td>\n","      <td>9.165151</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","    <tr>\n","      <th>5100457</th>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>6.00</td>\n","      <td>64.00</td>\n","      <td>5.317224</td>\n","      <td>5.317224</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>8.306729e+07</td>\n","      <td>9.5</td>\n","      <td>10.392305</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","    <tr>\n","      <th>8295876</th>\n","      <td>0.074212</td>\n","      <td>65.20</td>\n","      <td>6.00</td>\n","      <td>64.00</td>\n","      <td>3.375920</td>\n","      <td>3.375920</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>54.00</td>\n","      <td>8.298606e+07</td>\n","      <td>9.5</td>\n","      <td>10.392305</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>141.55</td>\n","      <td>Attack</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 47 columns</p>\n","</div>"],"text/plain":["         flow_duration  Header_Length  Protocol Type  Duration       Rate  \\\n","5279460       0.000000          54.00           6.00     64.00  11.306346   \n","6663301       0.145200         217.75           6.99     63.59  29.517406   \n","8559664       0.008476          13.74           1.42     66.31  12.492760   \n","6299347       0.000000          54.00           6.00     64.00  60.940691   \n","9878162       0.000000          54.00           6.00     64.00  31.855998   \n","5980310       0.000000          54.00           6.00     64.00   4.574341   \n","9817752       0.000000         160.38          16.83     63.36   0.473485   \n","8683320       0.000000           0.00           1.00     64.00  36.340593   \n","5100457       0.000000          54.00           6.00     64.00   5.317224   \n","8295876       0.074212          65.20           6.00     64.00   3.375920   \n","\n","             Srate  Drate  fin_flag_number  syn_flag_number  rst_flag_number  \\\n","5279460  11.306346    0.0              1.0              0.0              1.0   \n","6663301  29.517406    0.0              0.0              1.0              0.0   \n","8559664  12.492760    0.0              0.0              0.0              0.0   \n","6299347  60.940691    0.0              1.0              0.0              1.0   \n","9878162  31.855998    0.0              0.0              1.0              0.0   \n","5980310   4.574341    0.0              0.0              0.0              0.0   \n","9817752   0.473485    0.0              0.0              0.0              0.0   \n","8683320  36.340593    0.0              0.0              0.0              0.0   \n","5100457   5.317224    0.0              0.0              0.0              0.0   \n","8295876   3.375920    0.0              0.0              1.0              0.0   \n","\n","         ...         Std  Tot size           IAT  Number   Magnitue  \\\n","5279460  ...    0.000000     54.00  8.334454e+07     9.5  10.392305   \n","6663301  ...    9.031879     66.19  8.297354e+07     9.5  10.885608   \n","8559664  ...  549.066680    920.22  8.325338e+07     9.5  41.775523   \n","6299347  ...    0.000000     54.00  8.334495e+07     9.5  10.392305   \n","9878162  ...    0.000000     54.00  8.297255e+07     9.5  10.392305   \n","5980310  ...    0.000000     54.00  8.306855e+07     9.5  10.392305   \n","9817752  ...    1.959534    160.98  8.301122e+07     9.5  17.971541   \n","8683320  ...    0.000000     42.00  8.314999e+07     9.5   9.165151   \n","5100457  ...    0.000000     54.00  8.306729e+07     9.5  10.392305   \n","8295876  ...    0.000000     54.00  8.298606e+07     9.5  10.392305   \n","\n","             Radius     Covariance  Variance  Weight   label  \n","5279460    0.000000       0.000000      0.00  141.55  Attack  \n","6663301   12.765440     541.688358      0.29  141.55  Attack  \n","8559664  776.392424  317509.558997      0.95  141.55  Attack  \n","6299347    0.000000       0.000000      0.00  141.55  Attack  \n","9878162    0.000000       0.000000      0.00  141.55  Attack  \n","5980310    0.000000       0.000000      0.00  141.55  Attack  \n","9817752    2.778919      48.451831      0.08  141.55  Attack  \n","8683320    0.000000       0.000000      0.00  141.55  Attack  \n","5100457    0.000000       0.000000      0.00  141.55  Attack  \n","8295876    0.000000       0.000000      0.00  141.55  Attack  \n","\n","[10 rows x 47 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head(10)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1705010666108,"user":{"displayName":"Hiếu Võ","userId":"16914104909337499796"},"user_tz":-420},"id":"s7vQhiYs2Qr9","outputId":"6aeaa4e2-0e19-41a5-9647-3c349a3f4d18"},"outputs":[{"data":{"text/plain":["array([[0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1],\n","       [0, 1]], dtype=uint8)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["y = pd.get_dummies(df['label']).iloc[:, ::-1].to_numpy()\n","\n","y_labels = np.argmax(y, axis=1)\n","\n","y[0:10]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Label 0: 308331 occurrences\n","Label 1: 12784839 occurrences\n"]}],"source":["\n","# Đếm số lượng mỗi nhãn\n","label_counts = np.bincount(y_labels)\n","\n","# In ra số lượng mỗi nhãn\n","for i, count in enumerate(label_counts):\n","    print(f\"Label {i}: {count} occurrences\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4341,"status":"ok","timestamp":1705010670445,"user":{"displayName":"Hiếu Võ","userId":"16914104909337499796"},"user_tz":-420},"id":"b-Pr_cp1vio4"},"outputs":[],"source":["df.replace([np.inf, -np.inf], np.nan, inplace=True)\n","df.fillna(method='ffill', inplace=True)\n","scaler = MinMaxScaler()\n","X = df.iloc[:, :-1]\n","X = scaler.fit_transform(X)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1705010285692,"user":{"displayName":"Hiếu Võ","userId":"16914104909337499796"},"user_tz":-420},"id":"pE1Z1nAX3YYS","outputId":"4e882cad-be9f-4132-82c8-e4337fabbbd3"},"outputs":[{"data":{"text/plain":["array([[0.00000000e+00, 5.45159430e-06, 1.27659574e-01, 2.50980392e-01,\n","        1.34782152e-06, 1.34782152e-06, 0.00000000e+00, 1.00000000e+00,\n","        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.35135135e-01, 0.00000000e+00,\n","        1.21315055e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 4.52541733e-03, 2.06327373e-03, 2.87273772e-04,\n","        1.03819930e-03, 0.00000000e+00, 9.19117647e-04, 4.97165449e-01,\n","        6.07142857e-01, 9.00826420e-03, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 5.76970443e-01],\n","       [1.46024390e-06, 2.19830492e-05, 1.48723404e-01, 2.49372549e-01,\n","        3.51874905e-06, 3.51874905e-06, 0.00000000e+00, 0.00000000e+00,\n","        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 5.40540541e-03, 7.45440127e-02,\n","        0.00000000e+00, 1.39130435e-05, 2.19058050e-05, 1.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 5.26103469e-03, 2.10453920e-03, 8.30699990e-04,\n","        1.55654657e-03, 8.21359082e-04, 1.85278799e-03, 4.94952375e-01,\n","        6.07142857e-01, 1.26294956e-02, 8.20872573e-04, 3.77370789e-06,\n","        2.90000000e-01, 5.76970443e-01],\n","       [8.52444850e-08, 1.38712788e-06, 3.02127660e-02, 2.60039216e-01,\n","        1.48925300e-06, 1.48925300e-06, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 2.70270270e-03, 1.58604282e-03,\n","        0.00000000e+00, 4.63768116e-06, 3.12940072e-06, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 8.05551006e-02, 5.04006190e-02, 3.44115676e-02,\n","        7.26533632e-02, 4.99321255e-02, 6.72656250e-02, 4.96621699e-01,\n","        6.07142857e-01, 2.39385582e-01, 4.99253658e-02, 2.21195141e-03,\n","        9.50000000e-01, 5.76970443e-01],\n","       [0.00000000e+00, 5.45159430e-06, 1.27659574e-01, 2.50980392e-01,\n","        7.26469648e-06, 7.26469648e-06, 0.00000000e+00, 1.00000000e+00,\n","        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.35135135e-01, 0.00000000e+00,\n","        1.21315055e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 4.52541733e-03, 2.06327373e-03, 2.87273772e-04,\n","        1.03819930e-03, 0.00000000e+00, 9.19117647e-04, 4.97167902e-01,\n","        6.07142857e-01, 9.00826420e-03, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 5.76970443e-01],\n","       [0.00000000e+00, 5.45159430e-06, 1.27659574e-01, 2.50980392e-01,\n","        3.79753085e-06, 3.79753085e-06, 0.00000000e+00, 0.00000000e+00,\n","        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.93021412e-02,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 4.52541733e-03, 2.06327373e-03, 2.87273772e-04,\n","        1.03819930e-03, 0.00000000e+00, 9.19117647e-04, 4.94946480e-01,\n","        6.07142857e-01, 9.00826420e-03, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 5.76970443e-01],\n","       [0.00000000e+00, 5.45159430e-06, 1.27659574e-01, 2.50980392e-01,\n","        5.45303918e-07, 5.45303918e-07, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 4.52541733e-03, 2.06327373e-03, 2.87273772e-04,\n","        1.03819930e-03, 0.00000000e+00, 9.19117647e-04, 4.95519134e-01,\n","        6.07142857e-01, 9.00826420e-03, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 5.76970443e-01],\n","       [0.00000000e+00, 1.61912351e-05, 3.58085106e-01, 2.48470588e-01,\n","        5.64437800e-08, 5.64437800e-08, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 1.42299808e-02, 1.92297111e-02, 2.87273772e-03,\n","        1.03383524e-02, 1.78199992e-04, 9.11305147e-03, 4.95177175e-01,\n","        6.07142857e-01, 6.46457745e-02, 1.78696431e-04, 3.37542893e-07,\n","        8.00000000e-02, 5.76970443e-01],\n","       [0.00000000e+00, 0.00000000e+00, 2.12765957e-02, 2.50980392e-01,\n","        4.33213622e-06, 4.33213622e-06, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 3.43931717e-03, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.96004920e-01,\n","        6.07142857e-01, 2.77555756e-17, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 5.76970443e-01],\n","       [0.00000000e+00, 5.45159430e-06, 1.27659574e-01, 2.50980392e-01,\n","        6.33862454e-07, 6.33862454e-07, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 4.52541733e-03, 2.06327373e-03, 2.87273772e-04,\n","        1.03819930e-03, 0.00000000e+00, 9.19117647e-04, 4.95511618e-01,\n","        6.07142857e-01, 9.00826420e-03, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 5.76970443e-01],\n","       [7.46329722e-07, 6.58229534e-06, 1.27659574e-01, 2.50980392e-01,\n","        4.02441071e-07, 4.02441071e-07, 0.00000000e+00, 0.00000000e+00,\n","        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.72323553e-02,\n","        1.21315055e-03, 0.00000000e+00, 1.04313357e-05, 0.00000000e+00,\n","        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n","        1.00000000e+00, 4.52541733e-03, 2.06327373e-03, 2.87273772e-04,\n","        1.03819930e-03, 0.00000000e+00, 9.19117647e-04, 4.95027105e-01,\n","        6.07142857e-01, 9.00826420e-03, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00, 5.76970443e-01]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["X[0:10]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=75)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["y_train_labels = np.argmax(y_train, axis=1)\n","y_test_labels = np.argmax(y_test, axis=1)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Label 0: 61733 occurrences\n","Label 1: 2556901 occurrences\n"]}],"source":["\n","# Đếm số lượng mỗi nhãn\n","label_counts = np.bincount(y_test_labels)\n","#label_counts = np.bincount(y_train_labels)\n","\n","# In ra số lượng mỗi nhãn\n","for i, count in enumerate(label_counts):\n","    print(f\"Label {i}: {count} occurrences\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"background_save":true},"id":"2MbooI7p5BKT"},"outputs":[],"source":["from sklearn.metrics import classification_report, roc_auc_score\n","\n","def eval(model):\n","  # Dự đoán nhãn trên tập kiểm thử\n","  y_pred = model.predict(X_test)\n","\n","  # Chuyển đổi dự đoán thành nhãn cụ thể\n","  y_pred_labels = np.argmax(y_pred, axis=1)\n","  y_true_labels = np.argmax(y_test, axis=1)\n","\n","  # Tính toán F1-score, Recall và Precision\n","  report = classification_report(y_true_labels, y_pred_labels, target_names=None)\n","  print(report)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def build_model():\n","  n_features = X_train.shape[1]\n","  model = Sequential()\n","  model.add(Dense(512, input_dim=n_features, activation='relu'))  # Input layer và hidden layer đầu tiên\n","  model.add(Dropout(0.3))  # Thêm dropout để giảm overfitting\n","  model.add(Dense(256, activation='relu'))  # Thêm hidden layer thứ hai\n","  model.add(Dropout(0.3))  # Thêm dropout\n","  model.add(Dense(128, activation='relu'))  # Thêm hidden layer thứ hai\n","  model.add(Dropout(0.3))  # Thêm dropout\n","  model.add(Dense(64, activation='relu'))  # Thêm hidden layer thứ hai\n","  model.add(Dropout(0.3))  # Thêm dropout\n","  model.add(Dense(y_train.shape[1], activation='softmax'))  # Output layer\n","\n","  # Compile mô hình\n","  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","  return model"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-01-19 16:34:26.147046: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1927314624 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","81833/81833 [==============================] - 968s 12ms/step - loss: 0.0192 - accuracy: 0.9907 - val_loss: 0.0168 - val_accuracy: 0.9918\n","Epoch 2/10\n","81833/81833 [==============================] - 938s 11ms/step - loss: 0.0175 - accuracy: 0.9921 - val_loss: 0.0165 - val_accuracy: 0.9922\n","Epoch 3/10\n","81833/81833 [==============================] - 928s 11ms/step - loss: 0.0173 - accuracy: 0.9924 - val_loss: 0.0158 - val_accuracy: 0.9932\n","Epoch 4/10\n","81833/81833 [==============================] - 967s 12ms/step - loss: 0.0171 - accuracy: 0.9925 - val_loss: 0.0154 - val_accuracy: 0.9934\n","Epoch 5/10\n","81833/81833 [==============================] - 958s 12ms/step - loss: 0.0170 - accuracy: 0.9926 - val_loss: 0.0155 - val_accuracy: 0.9933\n","Epoch 6/10\n","81833/81833 [==============================] - 908s 11ms/step - loss: 0.0172 - accuracy: 0.9926 - val_loss: 0.0152 - val_accuracy: 0.9935\n","Epoch 7/10\n","81833/81833 [==============================] - 718s 9ms/step - loss: 0.0173 - accuracy: 0.9927 - val_loss: 0.0156 - val_accuracy: 0.9936\n","Epoch 8/10\n","81833/81833 [==============================] - 671s 8ms/step - loss: 0.0176 - accuracy: 0.9928 - val_loss: 0.0163 - val_accuracy: 0.9932\n","Epoch 9/10\n","81833/81833 [==============================] - 673s 8ms/step - loss: 0.0178 - accuracy: 0.9928 - val_loss: 0.0156 - val_accuracy: 0.9934\n","Epoch 10/10\n","81833/81833 [==============================] - 671s 8ms/step - loss: 0.0179 - accuracy: 0.9928 - val_loss: 0.0155 - val_accuracy: 0.9931\n","81833/81833 [==============================] - 151s 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.82      0.85     61733\n","           1       1.00      1.00      1.00   2556901\n","\n","    accuracy                           0.99   2618634\n","   macro avg       0.94      0.91      0.92   2618634\n","weighted avg       0.99      0.99      0.99   2618634\n","\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","model = build_model()\n","\n","# Huấn luyện mô hình\n","model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))\n","\n","eval(model)\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# dem so luong false / true"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# Tính tổng số mẫu\n","n_samples = X_train.shape[0]\n","\n","# Tính chỉ số cho việc chia tách\n","# Phần 1: 0 -> 5/10 * n_samples\n","# Phần 2: 5/10 * n_samples -> (5+3)/10 * n_samples\n","# Phần 3: (5+3)/10 * n_samples -> n_samples\n","indices = [int(5/10 * n_samples), int((5+3)/10 * n_samples)]\n","\n","# Chia dữ liệu\n","client_data = np.split(X_train, indices)\n","client_labels = np.split(y_train, indices)\n","\n","# client_data[0], client_labels[0] sẽ chứa 50% dữ liệu đầu tiên\n","# client_data[1], client_labels[1] sẽ chứa 30% dữ liệu tiếp theo\n","# client_data[2], client_labels[2] sẽ chứa 20% dữ liệu cuối cùng\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def fed_avg(models, data_distribution):\n","    \"\"\"\n","    models: danh sách các mô hình từ các node\n","    data_distribution: danh sách chứa số lượng dữ liệu mỗi node có\n","    \"\"\"\n","    # Tính tổng số mẫu dữ liệu\n","    total_data = sum(data_distribution)\n","\n","    # Khởi tạo trọng số trung bình\n","    avg_weights = [np.zeros_like(w) for w in models[0].get_weights()]\n","\n","    # Cộng trọng số từ tất cả mô hình, đã được nhân với tỷ lệ dữ liệu tương ứng\n","    for model, data_count in zip(models, data_distribution):\n","        for idx, layer_weights in enumerate(model.get_weights()):\n","            avg_weights[idx] += (layer_weights * data_count) / total_data\n","\n","    return avg_weights\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["global_model = build_model()"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":867398,"status":"error","timestamp":1705009327465,"user":{"displayName":"Hiếu Võ","userId":"16914104909337499796"},"user_tz":-420},"id":"CxGBQNIsDzH5","outputId":"dc9d41ea-4adf-47be-a3f4-6014f8184630"},"outputs":[{"name":"stdout","output_type":"stream","text":["Round  0  - Client  1\n","Round  0  - Client  2\n","Round  0  - Client  3\n","Round  0  - Evaluation:\n","81833/81833 [==============================] - 139s 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.05      1.00      0.10     61733\n","           1       1.00      0.57      0.72   2556901\n","\n","    accuracy                           0.58   2618634\n","   macro avg       0.53      0.78      0.41   2618634\n","weighted avg       0.98      0.58      0.71   2618634\n","\n","Round  1  - Client  1\n","Round  1  - Client  2\n","Round  1  - Client  3\n","Round  1  - Evaluation:\n","81833/81833 [==============================] - 139s 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.63      0.32      0.42     61733\n","           1       0.98      1.00      0.99   2556901\n","\n","    accuracy                           0.98   2618634\n","   macro avg       0.81      0.66      0.71   2618634\n","weighted avg       0.98      0.98      0.98   2618634\n","\n","Round  2  - Client  1\n","Round  2  - Client  2\n","Round  2  - Client  3\n","Round  2  - Evaluation:\n","81833/81833 [==============================] - 138s 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.53      0.56     61733\n","           1       0.99      0.99      0.99   2556901\n","\n","    accuracy                           0.98   2618634\n","   macro avg       0.79      0.76      0.78   2618634\n","weighted avg       0.98      0.98      0.98   2618634\n","\n","Round  3  - Client  1\n","Round  3  - Client  2\n","Round  3  - Client  3\n","Round  3  - Evaluation:\n","81833/81833 [==============================] - 138s 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.53      0.62     61733\n","           1       0.99      1.00      0.99   2556901\n","\n","    accuracy                           0.98   2618634\n","   macro avg       0.87      0.76      0.81   2618634\n","weighted avg       0.98      0.98      0.98   2618634\n","\n","Round  4  - Client  1\n","Round  4  - Client  2\n","Round  4  - Client  3\n","Round  4  - Evaluation:\n","30904/81833 [==========>...................] - ETA: 1:52"]}],"source":["num_rounds = 50\n","num_epochs = 3\n","batch_size = 32\n","\n","for round in range(num_rounds):\n","    local_models = []\n","    cnt = 1\n","    for client_X, client_y in zip(client_data, client_labels):\n","        print('Round ', round, ' - Client ', cnt)\n","        cnt += 1\n","        # Sao chép trọng số từ global model\n","        local_model = build_model()\n","        local_model.set_weights(global_model.get_weights())\n","\n","        # Huấn luyện mô hình cục bộ\n","        local_model.fit(client_X, client_y, epochs=num_epochs, batch_size=batch_size, verbose=0)\n","        local_models.append(local_model)\n","\n","    # Cập nhật global model dựa trên trung bình trọng số từ các mô hình cục bộ\n","    global_model.set_weights(fed_avg(local_models, [len(cli_dt) for cli_dt in client_data]))\n","\n","    print('Round ', round, ' - Evaluation:')\n","    eval(global_model)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMSDjvZ+MB3aEVf9ABRJwOt","mount_file_id":"1kw32fVpav4IPJJtK8yC8brhEcbQqd3Tn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
